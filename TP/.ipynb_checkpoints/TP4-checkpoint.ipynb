{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP4"
      ],
      "metadata": {
        "id": "Q6BfoslGdGug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SDsVwmAc_au"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e823qpntc_av"
      },
      "source": [
        "# Entraîner un classificateur\n",
        "\n",
        "Ça y est. Vous avez vu comment définir des réseaux de neurones, calculer les pertes et faire\n",
        "mises à jour des poids du réseau.\n",
        "\n",
        "\n",
        "## Et les données ?\n",
        "\n",
        "Généralement, lorsque vous devez traiter des données d'image, de texte, audio ou vidéo,\n",
        "vous pouvez utiliser des packages Python standard qui chargent des données dans un tableau numpy.\n",
        "Ensuite, vous pouvez convertir ce tableau en ``torch.*Tensor``.\n",
        "\n",
        "- Pour les images, des packages tels que Pillow, OpenCV sont utiles\n",
        "- Pour l'audio, des packages tels que scipy et librosa\n",
        "\n",
        "\n",
        "Spécifiquement pour la vision, un package appelé\n",
        "``torchvision``, possède des chargeurs de données pour les ensembles de données courants tels que\n",
        "ImageNet, CIFAR10, MNIST, etc. et transformateurs de données pour les images, à savoir,\n",
        "``torchvision.datasets`` et ``torch.utils.data.DataLoader``. C'est très pratique !\n",
        "\n",
        "Pour ce tutoriel, nous utiliserons l'ensemble de données CIFAR10.\n",
        "Voir des exemples sur le [lien](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "\n",
        "## Entraîner un classificateur d'images\n",
        "\n",
        "Nous allons suivre les étapes suivantes dans l'ordre :\n",
        "\n",
        "1. Charger et normaliser les ensembles de données de formation et de test CIFAR10 à l'aide\n",
        "   ``torchvision``\n",
        "2. Définir un réseau neuronal convolutif\n",
        "3. Définir une fonction de perte\n",
        "4. Entraîner le réseau sur le training set\n",
        "5. Testez le réseau sur les données de test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load and normalize CIFAR10\n",
        "\n",
        "En utilisant ``torchvision``, il est très facile de travailler avec Cifar10.\n"
      ],
      "metadata": {
        "id": "3EHRVyLstZYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CRT7stTc_aw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFwmjHj2c_aw"
      },
      "source": [
        "La sortie des ensembles de données torchvision sont des images PIL Image à valeurs dans [0, 1].\n",
        "Nous les transformons en tensors normalisés à valeurs dans [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUNxPal3c_ax"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Si vous utilisez Windows et que vous obtenez une erreur BrokenPipeError, essayez de définir\n",
        "    le num_worker de torch.utils.data.DataLoader() à 0.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1nczoMcc_ax"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trainloader et testloader nous permettront d’échantillonner des lots de données."
      ],
      "metadata": {
        "id": "St222F-JSY7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Quelles sont les classes du dataset ? ([link](https://www.cs.toronto.edu/~kriz/cifar.html)) </font>\n",
        "\n",
        "  <font color='blue'> **Question** : Combien d'images sont dans le training set ? </font>\n",
        "  \n",
        "  <font color='blue'> **Question** : Combien d'images sont dans le test set  ? </font>\n",
        "\n",
        "  <font color='blue'> **Question** : Que fait ```transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))``` ? Comment cela serait-il codé pour des images en noir et blanc ? </font>"
      ],
      "metadata": {
        "id": "8Bxd8HZxuex1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCyq52E-c_ax"
      },
      "source": [
        "Regardons quelques images du training set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OViYagGMc_ax"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "SK8qI7oUYTbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjq1Pm_tc_ax"
      },
      "source": [
        "### 2. Define a Convolutional Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Compléter la cellule suivante </font>\n",
        "\n"
      ],
      "metadata": {
        "id": "IVO7HGN-DsoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sms1esepc_ay"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(__, 120) #TODO\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, __) #TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net(images)"
      ],
      "metadata": {
        "id": "2Q6bsAwuadUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaEdNBUEc_ay"
      },
      "source": [
        "### 3. Define a Loss function and optimizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYIPeA_fc_ay"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "kkJNit8IHi17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsESdHFYc_az"
      },
      "source": [
        "### 4. Entraînement du réseau\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz8yHrEec_az"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5HaG97Yc_az"
      },
      "outputs": [],
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Que fait la cellule précedente ?\n",
        "\n",
        "  (Très important pour le projet !) </font>"
      ],
      "metadata": {
        "id": "4LPu7V86t_Mi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsCjLkUic_az"
      },
      "source": [
        "See [here](https://pytorch.org/docs/stable/notes/serialization.html)\n",
        "for more details on saving PyTorch models.\n",
        "\n",
        "### 5. Test du réseau\n",
        "\n",
        "Nous avons entraîné le réseau avec 2 passages sur l'ensemble de données de formation.\n",
        "Vérifions si le réseau a appris quelque chose.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hSRatv3c_a0"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnrGRYgqc_a0"
      },
      "source": [
        "Ensuite, chargeons à nouveau notre modèle enregistré (remarque : sauvegarder et recharger le modèle\n",
        "n'était pas nécessaire ici, nous l'avons fait uniquement pour illustrer comment procéder) :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcAvphgHc_a0"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itm8j58zc_a0"
      },
      "source": [
        "D'accord, voyons maintenant ce que le réseau neuronal pense de ces exemples ci-dessus :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrVRrHdOc_a0"
      },
      "outputs": [],
      "source": [
        "outputs = net(images)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Quelles sont les probabilités que la première image des « images » se trouve dans chaque classe ? </font>"
      ],
      "metadata": {
        "id": "y4-r3vOzEHso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE6vZhR4c_a0"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQiUexdjc_a1"
      },
      "source": [
        "Observons la matrice de confusion."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Qu'est-ce qui est fait dans la cellule suivante ? </font>"
      ],
      "metadata": {
        "id": "QtDU-3emNVjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb2EPeWPc_a1"
      },
      "outputs": [],
      "source": [
        "all_labels = torch.tensor([])\n",
        "all_predicted = torch.tensor([])\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_labels = torch.cat((all_labels, labels))\n",
        "        all_predicted = torch.cat((all_predicted, predicted))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'> **Question** : Compléter la cellule ci-dessous. </font>"
      ],
      "metadata": {
        "id": "C0BIABu9N6QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "t_test = #TODO\n",
        "t_pred = #TODO\n",
        "\n",
        "\n",
        "#Classification report\n",
        "print(classification_report(t_test,t_pred,target_names = classes))\n",
        "\n",
        "#Confusion matrix\n",
        "cm = confusion_matrix(t_test,t_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels = classes)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "AfIVT8qyNbNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  <font color='blue'> Exercise </font>"
      ],
      "metadata": {
        "id": "RpDYds3tceST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification, make_blobs, make_gaussian_quantiles\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import display, clear_output\n",
        "import torch"
      ],
      "metadata": {
        "id": "QivrfWQDZpAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, t = make_gaussian_quantiles(n_features=2, n_classes=3, n_samples=500)\n",
        "\n",
        "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=.4, random_state=12)\n",
        "# Number of points in each set:\n",
        "N_train = X_train.shape[0]\n",
        "N_test = X_test.shape[0]\n",
        "\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=t_train, s=50, edgecolor='k')\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], marker='P', c=t_test, s=50, edgecolor='k');\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "YNraF_AIfmy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "t_train = torch.tensor(t_train, dtype=torch.int64)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "t_test = torch.tensor(t_test, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "t4tbNjPgGQL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "d = 5\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2,d)\n",
        "        self.fc2 = nn.Linear(d, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net2 = Net()"
      ],
      "metadata": {
        "id": "ISO7cvQtGQ2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fc1.bias.requires_grad = False\n",
        "net.fc1.weight.requires_grad = False\n"
      ],
      "metadata": {
        "id": "8ku7lhKSGTE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "W1 =torch.randn(d,2)\n",
        "b1 = torch.randn(d)\n",
        "net.fc2.bias = torch.nn.Parameter(b1)\n",
        "net.fc2.weight = torch.nn.Parameter(W1)\n",
        "net2.fc2.bias = torch.nn.Parameter(b1)\n",
        "net2.fc2.weight = torch.nn.Parameter(W1)\n",
        "\n",
        "\n",
        "W2 =torch.randn(3,d)\n",
        "b2 = torch.randn(3)\n",
        "net.fc2.bias = torch.nn.Parameter(b2)\n",
        "net.fc2.weight = torch.nn.Parameter(W2)\n",
        "net2.fc2.bias = torch.nn.Parameter(b2)\n",
        "net2.fc2.weight = torch.nn.Parameter(W2)"
      ],
      "metadata": {
        "id": "5DCt5UVhGVOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.75)\n",
        "optimizer2 = optim.SGD(net2.parameters(), lr=0.75)"
      ],
      "metadata": {
        "id": "4fBkXkS1GXuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(10**3):  # loop over the dataset multiple times\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    optimizer2.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    output = net(X_train)\n",
        "    loss = criterion(output, t_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # forward + backward + optimize\n",
        "    output2 = net2(X_train)\n",
        "    loss2 = criterion(output2, t_train)\n",
        "    loss2.backward()\n",
        "    optimizer2.step()\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "sX_1qwGHGa-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize results:\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = 0.02\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                        np.arange(y_min, y_max, h))\n",
        "X_grid = np.hstack((xx.ravel(), yy.ravel()))\n",
        "\n",
        "N_grid = xx.ravel().shape[0]\n",
        "X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "feature_transform = lambda x : (net(torch.tensor(x, dtype=torch.float32).unsqueeze(0)).detach().numpy())\n",
        "feature_transform2 = lambda x : (net2(torch.tensor(x, dtype=torch.float32).unsqueeze(0)).detach().numpy())\n",
        "\n",
        "\n",
        "Phi_grid = feature_transform(X_grid)\n",
        "Phi_grid2 = feature_transform2(X_grid)\n",
        "\n",
        "Z =np.argmax(Phi_grid,axis=2)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "figure = plt.figure(figsize=(16, 8))\n",
        "ax = plt.subplot(1,2,1)\n",
        "ax.set_title(\"Input data\")\n",
        "ax.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=t_train, s=50, edgecolor='k')\n",
        "ax.scatter(X_test[:, 0], X_test[:, 1], marker='P', c=t_test, s=50, edgecolor='k')\n",
        "ax = plt.subplot(1,2,2)\n",
        "cmap = ListedColormap(['b','y','r','m','g','c'])\n",
        "plt.contourf(xx,yy,Z,  cmap = cmap, alpha=.8)\n",
        "ax.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=t_train, s=50, edgecolor='k')\n",
        "ax.scatter(X_test[:, 0], X_test[:, 1], marker='P', c=t_test, s=50, edgecolor='k')\n",
        "\n",
        "Z2 =np.argmax(Phi_grid2,axis=2)\n",
        "Z2 = Z2.reshape(xx.shape)\n",
        "figure = plt.figure(figsize=(16, 8))\n",
        "ax = plt.subplot(1,2,1)\n",
        "ax.set_title(\"Input data\")\n",
        "ax.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=t_train, s=50, edgecolor='k')\n",
        "ax.scatter(X_test[:, 0], X_test[:, 1], marker='P', c=t_test, s=50, edgecolor='k')\n",
        "ax = plt.subplot(1,2,2)\n",
        "cmap = ListedColormap(['b','y','r','m','g','c'])\n",
        "plt.contourf(xx,yy,Z2,  cmap = cmap, alpha=.8)\n",
        "ax.scatter(X_train[:, 0], X_train[:, 1], marker='o', c=t_train, s=50, edgecolor='k')\n",
        "ax.scatter(X_test[:, 0], X_test[:, 1], marker='P', c=t_test, s=50, edgecolor='k')"
      ],
      "metadata": {
        "id": "ucW7BL8fGbgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test image"
      ],
      "metadata": {
        "id": "mu0pIpwwHQHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/emilePi/denis'"
      ],
      "metadata": {
        "id": "I8hBSNCZHSBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import pylab as plt\n",
        "import numpy as np\n",
        "img = to_tensor(Image.open('./denis/denis.jpeg'))\n",
        "npimg = img.numpy()\n",
        "plt.imshow(np.transpose(npimg, (1, 2, 0)),cmap=plt.cm.gray)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MY0kTLbcHUwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "im_pil = Image.open('./denis/denis.jpeg')\n",
        "display(im_pil)"
      ],
      "metadata": {
        "id": "e8xhredvHWcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si cela ne fonctionne pas :\n",
        "\n",
        "1. Télécharger l'image à ce lien : https://github.com/emilePi/denis\n",
        "2. Enregistrer-la dans le dossier de votre choix\n",
        "3. Compléter la cellule ci-dessous en mettant PATH= \"le chemin vers le dossier précédent\". (Par exemple PATH = 'C:/Documents/Apprentissage pour l'image/Cours/TP4/')"
      ],
      "metadata": {
        "id": "NTxzMt8EHYXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH =\n",
        "\n",
        "import os\n",
        "os.chdir(PATH)\n",
        "\n",
        "im_pil = Image.open('./denis.jpeg')\n",
        "display(im_pil)"
      ],
      "metadata": {
        "id": "NQqYlM8xHcwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}